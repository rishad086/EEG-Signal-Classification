{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db264813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.metrics import classification_report,f1_score,accuracy_score,roc_curve,auc,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d33ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('D:/EEG project/amr.csv')\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['path']\n",
    "Y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (510):\n",
    "    X[i] = np.load(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ca1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9098a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf520e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('t.png',X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f5fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread('t.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0454294",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeecf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b846d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('t1.jpg',X[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab88d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ijpg = plt.imread('t1.jpg')\n",
    "ijpg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969323c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.46899614/0.27450982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06951a40",
   "metadata": {},
   "outputs": [],
   "source": [
    " 0.6572903/0.3607843"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d5c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d10f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<510:\n",
    "    if Y[i]==1:\n",
    "        a.append(i)\n",
    "    i = i + 1\n",
    "i=0\n",
    "while i<510:\n",
    "    if Y[i]==0:\n",
    "        b.append(i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(X[0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4a66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(X[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dceb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:\\EEG project\\Zero'\n",
    "# os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1_dir = 'D:\\EEG project\\One'\n",
    "# os.mkdir(base1_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e3ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseOne_dir = 'D:\\EEG project\\OneJPG'\n",
    "# os.mkdir(baseOne_dir)\n",
    "baseZero_dir = 'D:\\EEG project\\ZeroJPG'\n",
    "# os.mkdir(baseZero_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(14):\n",
    "    path=os.path.join(base_dir,f'AF_{5}{x}.png')\n",
    "    plt.imsave(path,X[0][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ef74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opencv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bda5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04311d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(X[0][2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7614029",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b9255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<510:\n",
    "    if Y[i]==0:\n",
    "        b.append(i)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f1c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2c7143",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf877e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "while j < 103:\n",
    "    k = 0 \n",
    "    while k < 14:\n",
    "        path=os.path.join(baseZero_dir,f'channel_{j}_{k}.jpg')\n",
    "        plt.imsave(path,X[b[j]][k])\n",
    "        k=k+1\n",
    "    j=j+1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8301d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "while j < 407:\n",
    "    k = 0 \n",
    "    while k < 14:\n",
    "        path=os.path.join(baseOne_dir,f'chOne_{j}_{k}.jpg')\n",
    "        plt.imsave(path,X[a[j]][k])\n",
    "        k=k+1\n",
    "    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b96a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fd2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'D:\\EEG project\\RunModel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset_dir,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c041a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(dataset_dir,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bffba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir = os.path.join(dataset_dir,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a83979",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = os.path.join(train_dir,'one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7201906",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(train_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zero = os.path.join(train_dir,'zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(train_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one = os.path.join(test_dir,'one')\n",
    "# os.mkdir(test_one)\n",
    "test_zero = os.path.join(test_dir,'zero')\n",
    "# os.mkdir(test_zero)\n",
    "val_one = os.path.join(val_dir,'one')\n",
    "# os.mkdir(val_one)\n",
    "val_zero = os.path.join(val_dir,'zero')\n",
    "# os.mkdir(val_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_src = 'D:\\EEG project\\dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d08094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_srcJPG = 'D:\\EEG project\\datasetJPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b641be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(orginal_srcJPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b826991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('D:\\EEG project\\zero0.png')\n",
    "img = img.resize((150,150))\n",
    "img.save('D:\\EEG project\\zero0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['zero{}.jpg'.format(i) for i in range(1442)]\n",
    "for f in fname:\n",
    "    imgPath = os.path.join(orginal_srcJPG,f)\n",
    "    imgT = Image.open(imgPath)\n",
    "    imgT = imgT.resize((150,150))\n",
    "    imgT.save(imgPath)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(5698)]\n",
    "for f in fname:\n",
    "    imgPathOne = os.path.join(orginal_srcJPG,f)\n",
    "    imgTOne = Image.open(imgPathOne)\n",
    "    imgTOne = imgTOne.resize((150,150))\n",
    "    imgTOne.save(imgPathOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df617cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da557e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.chdir('D:\\EEG project\\ZeroJPG')\n",
    "i=0\n",
    "for file in os.listdir(path):\n",
    "    new_file_name = \"zero{}.jpg\".format(i)\n",
    "    os.rename(file,new_file_name)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc28a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = os.chdir('D:\\EEG project\\OneJPG')\n",
    "i=0\n",
    "for file in os.listdir(path1):\n",
    "    new_file_name1 = \"one{}.jpg\".format(i)\n",
    "    os.rename(file,new_file_name1)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8941aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['zero{}.jpg'.format(i) for i in range(900)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(train_zero,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cbcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['zero{}.jpg'.format(i) for i in range(900,1143)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(test_zero,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70c2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['zero{}.jpg'.format(i) for i in range(1143,1442)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(val_zero,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(1442,1642)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(train_one,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34431b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(900)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(train_one,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff31037",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(900,1143)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(test_one,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0552ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(1143,1442)]\n",
    "for f in fname:\n",
    "    src = os.path.join(orginal_srcJPG,f)\n",
    "    dst = os.path.join(val_one,f)\n",
    "    shutil.copyfile(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6711f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "#Created sequential models using Keras\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38811415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(150, 150), \n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fad8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=20,\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=10)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e101539",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(train_dir,\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d31144",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=plt.imread('D:/EEG project/RunModel/test/zero/zero900.jpg')\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319a8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=model.evaluate_generator(test_generator)\n",
    "print(\"%s%s: %.2f%%\" % (\"evaluate \",model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324525e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_file = \"D:/EEG project/zero0.png\"\n",
    "image = plt.imread(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"D:/EEG project/RunModel/validation/zero/zero1376.jpg\", target_size=(150,150)\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "# score = float(predictions[0])\n",
    "# print(f\"This image is {100 * (1 - score):.2f}% cat and {100 * score:.2f}% dog.\")\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b5b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import math\n",
    "batch_size = 20\n",
    "img_size = (150,150)\n",
    "\n",
    "root_dir = \"D:/EEG project/RISHAD/\"\n",
    "\n",
    "model1 = models.Sequential()\n",
    "\n",
    "\n",
    "img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "datagen = img_gen.flow_from_directory(root_dir,\n",
    "                                        target_size=(img_size, img_size),\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode=None,\n",
    "                                        shuffle=False)\n",
    "num_images = len(datagen.filenames)\n",
    "num_epochs = int(math.ceil(num_images / batch_size))\n",
    "\n",
    "feature_list = model1.predict_generator(np.random.rand(datagen, num_epochs,verbose = True))\n",
    "\n",
    "\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47991794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# coding=utf-8\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Keras\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Flask utils\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:\\EEG project\\RunModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'D:\\EEG project\\RunModel'\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ef10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(img_path, model):\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size=(150,150))\n",
    "    x = keras.preprocessing.image.img_to_array(img)\n",
    "    x = tf.expand_dims(img_array, 0) \n",
    "    x = preprocess_input(x, mode='caffe')\n",
    "    preds = model.predict(x)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766ff1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daf32998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c8084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb05b88a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'convolutional_block' from 'tensorflow.python.keras.layers' (c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, Input,ZeroPadding2D,Conv2D,Activation,MaxPooling2D,convolutional_block\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'convolutional_block' from 'tensorflow.python.keras.layers' (c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import Dense, Flatten, Input,ZeroPadding2D,Conv2D,Activation,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99998d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "364709af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a07cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4142b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2406cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"D:\\EEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79830cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd663633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7140 files belonging to 2 classes.\n",
      "Using 5712 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'training',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb31f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7140 files belonging to 2 classes.\n",
      "Using 1428 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'validation',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "422bafbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Zero']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917039af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 55s 1us/step\n"
     ]
    }
   ],
   "source": [
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.ResNet50(\n",
    "    include_top = False,\n",
    "    input_shape = (180,180,3),\n",
    "    pooling='max', classes=2,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecd0e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512,activation='relu'))\n",
    "resnet_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "94618226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', use_bias=False, name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Scale(axis = 3, name = scale_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', use_bias=False, name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Scale(axis = 3, name = scale_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', use_bias=False, name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2c')(X)\n",
    "    X = Scale(axis = 3, name = scale_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2a5c2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):  \n",
    "    # defining name basis\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    scale_name_base = 'scale' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '2a', use_bias=False, kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Scale(axis=3, name = scale_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(F2, (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', use_bias=False, kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Scale(axis=3, name = scale_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(F3, (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', use_bias=False, kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '2c')(X)\n",
    "    X = Scale(axis=3, name=scale_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1', use_bias=False, kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(epsilon = eps, axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "    X_shortcut = Scale(axis=3, name=scale_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3a754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c65e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb539c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3669c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (180, 180, 3), classes = 2):\n",
    "    X_input = Input(input_shape)\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "    X = MaxPooling2D(pool_size=(2, 2),name='avg_pool')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75c82678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_3), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'bn_conv1/gamma:0' shape=(64,) dtype=float32>\n",
      "  <tf.Variable 'bn_conv1/beta:0' shape=(64,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'glorot_uniform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[59], line 8\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(input_shape, classes)\u001b[0m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m Activation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(X)\n\u001b[0;32m      7\u001b[0m X \u001b[38;5;241m=\u001b[39m MaxPooling2D((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(X)\n\u001b[1;32m----> 8\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mconvolutional_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m X \u001b[38;5;241m=\u001b[39m identity_block(X, \u001b[38;5;241m3\u001b[39m, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m256\u001b[39m], stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m identity_block(X, \u001b[38;5;241m3\u001b[39m, [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m256\u001b[39m], stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, block\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[58], line 16\u001b[0m, in \u001b[0;36mconvolutional_block\u001b[1;34m(X, f, filters, stage, block, s)\u001b[0m\n\u001b[0;32m     12\u001b[0m X_shortcut \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m##### MAIN PATH #####\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# First component of main path \u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X \u001b[38;5;241m=\u001b[39m Conv2D(F1, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), strides \u001b[38;5;241m=\u001b[39m (s,s), padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, name \u001b[38;5;241m=\u001b[39m conv_name_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2a\u001b[39m\u001b[38;5;124m'\u001b[39m, use_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, kernel_initializer \u001b[38;5;241m=\u001b[39m \u001b[43mglorot_uniform\u001b[49m(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))(X)\n\u001b[0;32m     17\u001b[0m X \u001b[38;5;241m=\u001b[39m BatchNormalization(epsilon \u001b[38;5;241m=\u001b[39m eps, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, name \u001b[38;5;241m=\u001b[39m bn_name_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2a\u001b[39m\u001b[38;5;124m'\u001b[39m)(X)\n\u001b[0;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m Scale(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, name \u001b[38;5;241m=\u001b[39m scale_name_base \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2a\u001b[39m\u001b[38;5;124m'\u001b[39m)(X)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glorot_uniform' is not defined"
     ]
    }
   ],
   "source": [
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9cd46e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " module_wrapper (ModuleWrapp  (None, 2048)             0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWra  (None, 512)              1049088   \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " module_wrapper_2 (ModuleWra  (None, 2)                1026      \n",
      " pper)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,637,826\n",
      "Trainable params: 1,050,114\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eab91652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "resnet_model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "179/179 [==============================] - 353s 2s/step - loss: 0.9566 - accuracy: 0.7726 - val_loss: 0.4845 - val_accuracy: 0.8123\n",
      "Epoch 2/20\n",
      "179/179 [==============================] - 340s 2s/step - loss: 0.4714 - accuracy: 0.8127 - val_loss: 0.5004 - val_accuracy: 0.8102\n",
      "Epoch 3/20\n",
      "179/179 [==============================] - 339s 2s/step - loss: 0.4465 - accuracy: 0.8148 - val_loss: 0.4260 - val_accuracy: 0.8270\n",
      "Epoch 4/20\n",
      "179/179 [==============================] - 339s 2s/step - loss: 0.3896 - accuracy: 0.8321 - val_loss: 0.3981 - val_accuracy: 0.8340\n",
      "Epoch 5/20\n",
      "179/179 [==============================] - 337s 2s/step - loss: 0.3815 - accuracy: 0.8351 - val_loss: 0.3810 - val_accuracy: 0.8347\n",
      "Epoch 6/20\n",
      "179/179 [==============================] - 332s 2s/step - loss: 0.3656 - accuracy: 0.8489 - val_loss: 0.3829 - val_accuracy: 0.8382\n",
      "Epoch 7/20\n",
      "179/179 [==============================] - 333s 2s/step - loss: 0.3565 - accuracy: 0.8442 - val_loss: 0.3923 - val_accuracy: 0.8368\n",
      "Epoch 8/20\n",
      "179/179 [==============================] - 338s 2s/step - loss: 0.3408 - accuracy: 0.8517 - val_loss: 0.3855 - val_accuracy: 0.8375\n",
      "Epoch 9/20\n",
      "179/179 [==============================] - 340s 2s/step - loss: 0.3140 - accuracy: 0.8608 - val_loss: 0.3848 - val_accuracy: 0.8375\n",
      "Epoch 10/20\n",
      "179/179 [==============================] - 340s 2s/step - loss: 0.3189 - accuracy: 0.8615 - val_loss: 0.4010 - val_accuracy: 0.8375\n",
      "Epoch 11/20\n",
      "179/179 [==============================] - 342s 2s/step - loss: 0.3158 - accuracy: 0.8633 - val_loss: 0.3858 - val_accuracy: 0.8354\n",
      "Epoch 12/20\n",
      "179/179 [==============================] - 365s 2s/step - loss: 0.2946 - accuracy: 0.8734 - val_loss: 0.3936 - val_accuracy: 0.8319\n",
      "Epoch 13/20\n",
      "179/179 [==============================] - 405s 2s/step - loss: 0.2817 - accuracy: 0.8759 - val_loss: 0.4620 - val_accuracy: 0.7710\n",
      "Epoch 14/20\n",
      "179/179 [==============================] - 448s 3s/step - loss: 0.2755 - accuracy: 0.8818 - val_loss: 0.4044 - val_accuracy: 0.8361\n",
      "Epoch 15/20\n",
      " 79/179 [============>.................] - ETA: 3:07 - loss: 0.2520 - accuracy: 0.8928"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = resnet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a925fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "  import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5a39756",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ONE = 'D:\\EEG project\\datasetJPG\\ONE'\n",
    "dir_ZERO = 'D:\\EEG project\\datasetJPG\\ZERO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d35affb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZERO'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgpath = 'D:\\EEG project\\datasetJPG\\ZERO\\zero0.jpg'\n",
    "image = cv2.imread(imgpath)\n",
    "image_resize = cv2.resize(image,(img_height,img_width))\n",
    "image = np.expand_dims(image_resize,axis=0)\n",
    "image.shape\n",
    "pred = resnet_model.predict(image)\n",
    "output = class_names[np.argmax(pred)]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac2d1b04",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m imgpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEEG project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdatasetJPG\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mZERO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;132;01m{i}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(imgpath)\n\u001b[1;32m----> 4\u001b[0m image_resize \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image_resize,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      6\u001b[0m image\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    imgpath = 'D:\\EEG project\\datasetJPG\\ZERO\\zero{i}.jpg'\n",
    "    image = cv2.imread(imgpath)\n",
    "    image_resize = cv2.resize(image,(img_height,img_width))\n",
    "    image = np.expand_dims(image_resize,axis=0)\n",
    "    image.shape\n",
    "    pred = resnet_model.predict(image)\n",
    "    output = class_names[np.argmax(pred)]\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6eb04870",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc7c28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_srcJPG = 'D:\\EEG project\\datasetJPG\\ONE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4976b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n",
      "(1, 180, 180, 3)\n"
     ]
    }
   ],
   "source": [
    "fname = ['one{}.jpg'.format(i) for i in range(100,200)]\n",
    "for f in fname:\n",
    "    imgpath = os.path.join(orginal_srcJPG,f)\n",
    "    image = cv2.imread(imgpath)\n",
    "    image_resize = cv2.resize(image,(img_height,img_width))\n",
    "    image = np.expand_dims(image_resize,axis=0)\n",
    "    print(image.shape)\n",
    "#     pred = resnet_model.predict(image)\n",
    "#     output = class_names[np.argmax(pred)]\n",
    "#     print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "83a1eb44",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [129], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m z\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZERO\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m      4\u001b[0m         z\u001b[38;5;241m=\u001b[39mz\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "z=0\n",
    "for k in range(100):\n",
    "    if result[k]=='ZERO':\n",
    "        z=z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.applications.EfficientNetB0(\n",
    "#     include_top=True,\n",
    "#     weights=\"imagenet\",\n",
    "#     input_tensor=None,\n",
    "#     input_shape=None,\n",
    "#     pooling=None,\n",
    "#     classes=1000,\n",
    "#     classifier_activation=\"softmax\",\n",
    "#     **kwargs\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ef7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.ResNet50(\n",
    "    include_top = False,\n",
    "    input_shape = (150,150,3),\n",
    "    pooling='max', classes=2,\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90838259",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.EfficientNetV2L(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    "    include_preprocessing=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2830127",
   "metadata": {},
   "source": [
    "## EfficienNets B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5b6d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'Zero']\n",
      "Types of classes labels found:  2\n",
      "  Labels                         image\n",
      "0    One     dataset_path/One/one1.jpg\n",
      "1    One    dataset_path/One/one10.jpg\n",
      "2    One   dataset_path/One/one100.jpg\n",
      "3    One  dataset_path/One/one1000.jpg\n",
      "4    One  dataset_path/One/one1001.jpg\n",
      "     Labels                          image\n",
      "2781   Zero  dataset_path/Zero/zero995.jpg\n",
      "2782   Zero  dataset_path/Zero/zero996.jpg\n",
      "2783   Zero  dataset_path/Zero/zero997.jpg\n",
      "2784   Zero  dataset_path/Zero/zero998.jpg\n",
      "2785   Zero  dataset_path/Zero/zero999.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir( r\"D:\\EEG project\\RISHAD\")\n",
    "\n",
    "print (dataset_path)  #what kinds of classes are in this dataset\n",
    "\n",
    "print(\"Types of classes labels found: \", len(dataset_path))\n",
    "\n",
    "class_labels = []\n",
    "\n",
    "for item in dataset_path:\n",
    " # Get all the file names\n",
    " all_classes = os.listdir('D:\\EEG project\\RISHAD' + '/' +item)\n",
    " #print(all_classes)\n",
    "\n",
    " # Add them to the list\n",
    " for room in all_classes:\n",
    "    class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))\n",
    "    #print(class_labels[:5])\n",
    "    \n",
    "    \n",
    "# Build a dataframe        \n",
    "df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab6e0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in the dataset:  2786\n",
      "Zero    1442\n",
      "One     1344\n",
      "Name: Labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of images in the dataset: \", len(df))\n",
    "\n",
    "label_count = df['Labels'].value_counts()\n",
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b00240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "path = 'D:/EEG project/RISHAD/'\n",
    "dataset_path = os.listdir(r'D:\\EEG project\\RISHAD')\n",
    "\n",
    "im_size = 224\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in dataset_path:\n",
    "    data_path = path + str(i)  \n",
    "    filenames = [i for i in os.listdir(data_path) ]\n",
    "   \n",
    "    for f in filenames:\n",
    "        img = cv2.imread(data_path + '/' + f)\n",
    "        img = cv2.resize(img, (im_size, im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51807467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2786, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "\n",
    "images = images.astype('int') / 255.0\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea86cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One' 'One' 'One' ... 'Zero' 'Zero' 'Zero']\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "y=df['Labels'].values\n",
    "print(y)\n",
    "\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020a434d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y=y.reshape(-1,1)\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "Y = ct.fit_transform(y) #.toarray()\n",
    "print(Y[:5])\n",
    "print(Y[35:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f115e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2646, 224, 224, 3)\n",
      "(2646, 2)\n",
      "(140, 224, 224, 3)\n",
      "(140, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "images, Y = shuffle(images, Y, random_state=1)\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.05, random_state=415)\n",
    "\n",
    "#inpect the shape of the training and testing.\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f90209ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "IMG_SIZE = 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94532556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    #x = img_augmentation(inputs)\n",
    "    x = inputs\n",
    "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582540c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9c28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    #plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#plot_hist(hist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc4dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "83/83 - 117s - loss: 0.9202 - accuracy: 0.5094 - 117s/epoch - 1s/step\n",
      "Epoch 2/20\n",
      "83/83 - 82s - loss: 0.8593 - accuracy: 0.5049 - 82s/epoch - 986ms/step\n",
      "Epoch 3/20\n",
      "83/83 - 79s - loss: 0.8294 - accuracy: 0.4958 - 79s/epoch - 952ms/step\n",
      "Epoch 4/20\n",
      "83/83 - 81s - loss: 0.7643 - accuracy: 0.5147 - 81s/epoch - 971ms/step\n",
      "Epoch 5/20\n",
      "83/83 - 79s - loss: 0.7814 - accuracy: 0.4977 - 79s/epoch - 953ms/step\n",
      "Epoch 6/20\n",
      "83/83 - 80s - loss: 0.7733 - accuracy: 0.5045 - 80s/epoch - 966ms/step\n",
      "Epoch 7/20\n",
      "83/83 - 81s - loss: 0.7607 - accuracy: 0.4970 - 81s/epoch - 973ms/step\n",
      "Epoch 8/20\n",
      "83/83 - 82s - loss: 0.7765 - accuracy: 0.5015 - 82s/epoch - 989ms/step\n",
      "Epoch 9/20\n",
      "83/83 - 80s - loss: 0.7377 - accuracy: 0.5060 - 80s/epoch - 966ms/step\n",
      "Epoch 10/20\n",
      "83/83 - 83s - loss: 0.7326 - accuracy: 0.5011 - 83s/epoch - 997ms/step\n",
      "Epoch 11/20\n",
      "83/83 - 86s - loss: 0.7378 - accuracy: 0.5231 - 86s/epoch - 1s/step\n",
      "Epoch 12/20\n",
      "83/83 - 83s - loss: 0.7374 - accuracy: 0.4887 - 83s/epoch - 995ms/step\n",
      "Epoch 13/20\n",
      "83/83 - 95s - loss: 0.7363 - accuracy: 0.4977 - 95s/epoch - 1s/step\n",
      "Epoch 14/20\n",
      "83/83 - 85s - loss: 0.7290 - accuracy: 0.5094 - 85s/epoch - 1s/step\n",
      "Epoch 15/20\n",
      "83/83 - 87s - loss: 0.7281 - accuracy: 0.4974 - 87s/epoch - 1s/step\n",
      "Epoch 16/20\n",
      "83/83 - 86s - loss: 0.7173 - accuracy: 0.4917 - 86s/epoch - 1s/step\n",
      "Epoch 17/20\n",
      "83/83 - 84s - loss: 0.7363 - accuracy: 0.5045 - 84s/epoch - 1s/step\n",
      "Epoch 18/20\n",
      "83/83 - 80s - loss: 0.7156 - accuracy: 0.5030 - 80s/epoch - 968ms/step\n",
      "Epoch 19/20\n",
      "83/83 - 81s - loss: 0.7069 - accuracy: 0.5094 - 81s/epoch - 981ms/step\n",
      "Epoch 20/20\n",
      "83/83 - 80s - loss: 0.7060 - accuracy: 0.5042 - 80s/epoch - 970ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 20 \n",
    "hist = model.fit(train_x, train_y, epochs=epochs, verbose=2)\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c900f8",
   "metadata": {},
   "source": [
    "\n",
    "## EfficientNetB7 Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1625b364",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"D:\\EEG project\\datasetJPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "225037e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 600\n",
    "img_width = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f5f5d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7140 files belonging to 2 classes.\n",
      "Using 5712 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'training',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f350f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7140 files belonging to 2 classes.\n",
      "Using 1428 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'validation',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "675b0b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ONE', 'ZERO']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93e2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.EfficientNetB7(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    \n",
    "    input_shape=(600,600,3),\n",
    "    pooling='max',\n",
    "    classes=2,\n",
    "    classifier_activation=\"softmax\",\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5370dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512,activation='relu'))\n",
    "resnet_model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9684ba17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional)  (None, 2560)             64097687  \n",
      "                                                                 \n",
      " module_wrapper (ModuleWrapp  (None, 2560)             0         \n",
      " er)                                                             \n",
      "                                                                 \n",
      " module_wrapper_1 (ModuleWra  (None, 512)              1311232   \n",
      " pper)                                                           \n",
      "                                                                 \n",
      " module_wrapper_2 (ModuleWra  (None, 2)                1026      \n",
      " pper)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,409,945\n",
      "Trainable params: 1,312,258\n",
      "Non-trainable params: 64,097,687\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\python\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "resnet_model.summary()\n",
    "resnet_model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  7/179 [>.............................] - ETA: 3:08:58 - loss: 17.3298 - accuracy: 0.7545"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "history = resnet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data = val_ds,\n",
    "    epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d608a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4c6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cee88b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf557f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9b140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02954c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83c539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d871e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a16b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b9278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80838c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'training',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1c57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=0.2,\n",
    "    subset = 'validation',\n",
    "    seed = 2022,\n",
    "    label_mode ='categorical',\n",
    "    image_size = (img_height, img_width),\n",
    "    batch_size = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d10960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f7d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d0ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6b5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a108d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a6a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427eae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69591015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
